{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Stores and Retrievers\n",
    "Use Vectors Database and integrate with LLM workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents\n",
    "Langchain implements a Document abstraction. It has 2 attributes: \n",
    "- page_content\n",
    "- metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'type': 'dog', 'trait': 'loyalty'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
       " Document(metadata={'type': 'cat', 'trait': 'independence'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
       " Document(metadata={'type': 'fish', 'trait': 'low maintenance'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
       " Document(metadata={'type': 'bird', 'trait': 'intelligence'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
       " Document(metadata={'type': 'rabbit', 'trait': 'social'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://python.langchain.com/docs/how_to/custom_retriever/\n",
    "# ___________________________________________________________\n",
    "# Document Setup\n",
    "from langchain_core.documents import Document \n",
    "\n",
    "# Initialize a list of documents with page content and associated metadata\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"type\": \"dog\", \"trait\": \"loyalty\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"type\": \"cat\", \"trait\": \"independence\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
    "        metadata={\"type\": \"fish\", \"trait\": \"low maintenance\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
    "        metadata={\"type\": \"bird\", \"trait\": \"intelligence\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
    "        metadata={\"type\": \"rabbit\", \"trait\": \"social\"},\n",
    "    ),\n",
    "]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "import os  # Import the os module for environment variable handling\n",
    "from dotenv import load_dotenv  # Import dotenv to load environment variables from .env files\n",
    "\n",
    "load_dotenv()  # Load the environment variables from .env files\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\") # Retrieve the Groq API key from environment variables\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\") # Retrieve the Hugging Face API key from environment variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000243A333C690>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000243A32F3A10>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Initialization\n",
    "from langchain_groq import ChatGroq # Import the ChatGroq class from langchain_groq\n",
    "\n",
    "# Initialize the language model instance\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model=\"Llama3-8b-8192\")\n",
    "llm\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # Import for embedding generation\n",
    "# Initialize HuggingFace embeddings with a specific model\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# VectorStores\n",
    "from langchain_chroma import Chroma # Import Chroma for vector storage\n",
    "\n",
    "# Create a vector store from the documents using embeddings\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embeddings)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search on the vector store\n",
    "vectorstore.similarity_search(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an asynchronous similarity search\n",
    "await vectorstore.asimilarity_search(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search with scores\n",
    "vectorstore.similarity_search_with_score(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrievers \n",
    "VectorStore objects do not subclass Runnable, so can't be integrated in LCEL. However, Retrievers can (synchronous, asynchronous and batch operations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever Setup\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document # Re-import for type hinting\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Create a retriever using a lambda function for similarity search\n",
    "retriever=RunnableLambda(vectorstore.similarity_search).bind(k=1)\n",
    "\n",
    "# Batch process similarity search queries\n",
    "retriever.batch([\"cat\",\"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure retriever with specific search types and parameters\n",
    "retriever=vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":1}\n",
    ")\n",
    "# Execute batch retrieval with the configured retriever\n",
    "retriever.batch([\"cat\",\"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG (Retrieval-Augmented Generation)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define a message template for RAG\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# Create a prompt template from the message for conversational bots\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "# Define a retrieval-augmented generation chain\n",
    "rag_chain={\"context\":retriever,\"question\":RunnablePassthrough()}|prompt|llm\n",
    "\n",
    "# Invoke the RAG chain with a query\n",
    "response=rag_chain.invoke(\"Tell me about dogs\")\n",
    "print(response.content) # Output the content of the response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91146359afa204c864d2e8c089978309c47dcbcfea673fcbf773823672987b6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
